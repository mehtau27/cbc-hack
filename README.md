# Dance Choreography Comparison System

An AI-powered web application that compares student dance performances to example choreography using computer vision and pose estimation. Perfect for dance teams, instructors, and students who want automated, objective feedback on choreography accuracy.

## Features

- **Pose Estimation**: Uses MediaPipe to extract 33 body keypoints from videos
- **Intelligent Comparison**: Dynamic Time Warping (DTW) aligns sequences accounting for timing differences
- **Detailed Scoring**: Get percentage breakdowns for:
  - Pose Accuracy
  - Timing Accuracy
  - Movement Smoothness
  - Angle Accuracy
- **AI-Powered Feedback**: Natural language feedback generated by GPT-4
- **Configurable Focus Areas**: Choose to emphasize specific body parts (arms, legs, upper body, etc.)
- **Report Generation**: Save and review comparison reports
- **Web Interface**: Modern, responsive UI for easy video upload and results viewing

## How It Works

1. **Upload**: Captain uploads example choreography video
2. **Student Submit**: Student uploads their performance video
3. **Analyze**: System extracts pose keypoints from both videos
4. **Align**: DTW algorithm aligns the sequences temporally
5. **Compare**: Calculate similarity metrics across multiple dimensions
6. **Feedback**: AI generates specific, actionable improvement suggestions

## Technical Stack

- **Backend**: FastAPI, Python
- **Computer Vision**: MediaPipe, OpenCV
- **Alignment**: Dynamic Time Warping (DTW)
- **AI Feedback**: OpenAI GPT-4
- **Frontend**: HTML, CSS, JavaScript
- **Analysis**: NumPy, SciPy

## Setup Instructions

### Prerequisites

- Python 3.8 or higher
- OpenAI API key
- Webcam or pre-recorded videos

### 1. Install Dependencies

```bash
# Create virtual environment (if not already created)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install packages
pip install -r requirements.txt
```

### 2. Configure API Key

Create or edit `.env` file:

```bash
OPENAI_API_KEY=your_openai_api_key_here
```

Get your API key from: https://platform.openai.com/api-keys

### 3. Run the Application

```bash
python app.py
```

The application will start on http://localhost:8000

## Usage Guide

### For Captains/Instructors

1. Record your example choreography video
2. Upload it as the "Example Video"
3. Students will submit their attempts
4. Review automated comparison reports

### For Students

1. Record your choreography performance
2. Upload as "Assignment Video"
3. Select the example video to compare against
4. Enter your name (optional)
5. Choose focus areas if specified by instructor
6. Click "Compare Videos"
7. Review your score and feedback
8. Practice specific issues mentioned in feedback

### Focus Areas

You can configure the system to emphasize specific body parts:

- **Full Body**: Default, tracks all movements
- **Upper Body**: Focus on torso, arms, shoulders
- **Arms**: Emphasize arm positions and movements
- **Legs**: Focus on leg movements and footwork
- **Lower Body**: Emphasize hips, legs, feet

## Example Output

```
Overall Match: 78%

Breakdown:
- Pose Accuracy: 82%
- Timing Accuracy: 75%
- Movement Smoothness: 70%
- Angle Accuracy: 85%

AI Feedback:
"Your choreography shows strong fundamentals with good arm extension and timing.
Focus on:
1. [0:15-0:25] Increase speed of arm movements by ~15%
2. [0:45] Extend right arm fully during wave
3. [1:10-1:20] Smoother transitions - current movements appear stiff
4. [1:35] More pronounced hip rotation needed

Keep practicing the mid-section transitions. Great job overall!"
```

## Project Structure

```
cbc-hack/
├── app.py                          # FastAPI main application
├── requirements.txt                # Python dependencies
├── .env                           # Environment variables
├── .gitignore                     # Git ignore rules
├── README.md                      # This file
├── services/
│   ├── __init__.py
│   ├── pose_extraction_service.py # MediaPipe pose extraction
│   ├── comparison_service.py      # DTW alignment & comparison
│   └── feedback_service.py        # AI feedback generation
├── static/
│   ├── index.html                 # Frontend HTML
│   ├── style.css                  # Styling
│   └── script.js                  # Frontend logic
├── uploads/                       # Uploaded videos (auto-created)
└── reports/                       # Saved reports (auto-created)
```

## API Endpoints

- `POST /upload-example` - Upload example video
- `POST /upload-assignment` - Upload student video
- `POST /extract-poses` - Extract pose data from video
- `POST /compare` - Compare two videos
- `GET /reports` - List all saved reports
- `GET /reports/{filename}` - Get specific report
- `DELETE /reports/{filename}` - Delete a report

## Technical Details

### Pose Estimation

Uses MediaPipe Pose which provides:
- 33 3D body keypoints
- X, Y, Z coordinates
- Visibility scores
- Calculated joint angles

### Comparison Metrics

1. **Pose Similarity**: Cosine similarity between pose feature vectors
2. **Timing Accuracy**: DTW alignment quality score
3. **Angle Similarity**: Euclidean distance between joint angles
4. **Smoothness**: Inverse of movement jerk (acceleration changes)

### Scoring Algorithm

```python
Overall Score =
    0.40 * Pose Similarity +
    0.25 * Timing Accuracy +
    0.20 * Angle Accuracy +
    0.15 * Smoothness Score
```

## Customization

### Adjust Similarity Threshold

Edit `services/comparison_service.py`:

```python
self.similarity_threshold = 0.7  # Default threshold
```

### Change Score Weights

Modify weights in `_calculate_overall_score()`:

```python
weights = {
    'pose_similarity': 0.40,   # Adjust these
    'timing_similarity': 0.25,
    'angle_similarity': 0.20,
    'smoothness': 0.15
}
```

### MediaPipe Model Complexity

Edit `services/pose_extraction_service.py`:

```python
model_complexity=2  # 0 (fastest), 1, or 2 (most accurate)
```

## Troubleshooting

### "Module not found" errors
```bash
pip install -r requirements.txt
```

### API key errors
Ensure `.env` file exists with valid OpenAI API key

### Pose detection failing
- Ensure good lighting in videos
- Subject should be fully visible
- Try different camera angles
- Check video quality/resolution

### Slow processing
- Use shorter videos for testing
- Reduce MediaPipe model complexity
- Process videos at lower resolution

## Performance Tips

1. **Video Length**: Keep videos under 2 minutes for faster processing
2. **Resolution**: 720p is sufficient, 4K is unnecessary
3. **Lighting**: Well-lit videos improve pose detection accuracy
4. **Framing**: Ensure full body is visible in frame
5. **Background**: Plain backgrounds work best

## Future Enhancements

- Real-time webcam comparison
- Side-by-side video playback with skeleton overlay
- Mobile app version
- Multi-person choreography comparison
- Progress tracking over time
- Export reports as PDF
- Video trimming/editing tools
- Slow-motion analysis
- Batch processing for multiple students

## Use Cases

- **Dance Teams**: Automated homework grading
- **Dance Studios**: Student progress tracking
- **Online Classes**: Remote performance evaluation
- **Competitions**: Objective scoring assistance
- **Personal Practice**: Self-improvement feedback

## License

MIT License - feel free to use and modify for your projects!

## Contributing

Contributions welcome! Please feel free to submit a Pull Request.

## Support

For issues or questions, please open an issue on GitHub.
